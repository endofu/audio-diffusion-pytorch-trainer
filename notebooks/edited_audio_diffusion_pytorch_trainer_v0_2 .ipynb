{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Welcome to the ADPT ([`audio-diffusion-pytorch-trainer`](https://github.com/archinetai/audio-diffusion-pytorch-trainer)) notebook beta v0.2!"
      ],
      "metadata": {
        "id": "GW5-6bxDz8At"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this notebook**:\n",
        "\n",
        "- Train larger than 1B params model. The results are faster and produces better quality music, generating longer audio tracks in one go â€“ up to 87s of context without inpainting at 48kHz!\n",
        "\n",
        "Use these models for:\n",
        "- Unconditional audio sample generation\n",
        "- Infinite audio generation with inpainting!\n",
        "- Follow the notebook discussions [here](https://github.com/archinetai/audio-diffusion-pytorch/discussions/categories/notebooks)\n"
      ],
      "metadata": {
        "id": "uUmF8O8t0Iz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title <- View Changelog\n",
        "skip_for_run_all = True #@param {type: 'boolean'}\n",
        "\n",
        "if skip_for_run_all == False:\n",
        "  print(\n",
        "      '''\n",
        "  v0.1 Update: Set 11, 2022 - flavioschneider\n",
        "\n",
        "      - Added Dance Diffusion finetune repo\n",
        "\n",
        "  v0.2 Update: Oct 29, 2022 - twobob\n",
        "\n",
        "      - added changelog, experiment editor, multiplatform support, and .env generator\n",
        "      '''\n",
        "      )"
      ],
      "metadata": {
        "cellView": "form",
        "id": "_8QembxYsdkk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Check GPU Status\n",
        "import shutil\n",
        "def is_tool(name):\n",
        "    \"\"\"Check whether `name` is on PATH and marked as executable.\"\"\"\n",
        "\n",
        "    # from whichcraft import which\n",
        "    from shutil import which\n",
        "\n",
        "    return which(name) is not None\n",
        "skip_for_run_all = True #@param {type: 'boolean'}\n",
        "\n",
        "import subprocess\n",
        "if skip_for_run_all == False:\n",
        "  if is_tool('nvidia-smi'):\n",
        "    simple_nvidia_smi_display = True#@param {type:\"boolean\"}\n",
        "    if simple_nvidia_smi_display:\n",
        "        #!nvidia-smi\n",
        "        nvidiasmi_output = subprocess.run(['nvidia-smi', '-L'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        print(nvidiasmi_output)\n",
        "    else:\n",
        "        #!nvidia-smi -i 0 -e 0\n",
        "        nvidiasmi_output = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        print(nvidiasmi_output)\n",
        "        nvidiasmi_ecc_note = subprocess.run(['nvidia-smi', '-i', '0', '-e', '0'], stdout=subprocess.PIPE).stdout.decode('utf-8')\n",
        "        print(nvidiasmi_ecc_note)\n",
        "  else:\n",
        "    print('Your system does not have nvidia-smi available as a command')\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nZ8aof860KRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Cleardown options\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "from IPython.display import clear_output\n",
        "from os.path import exists\n",
        "from pathlib import Path\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HBox, Label\n",
        "from ipywidgets import Layout, Button, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
        "clear_logs_after_setup = False#@param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "t-aJtV8x0-o8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from google.colab import drive\n",
        "    print(\"Google Colab detected. Using Google Drive.\")\n",
        "    is_colab = True\n",
        "    is_kaggle = False\n",
        "    #@markdown Check to connect your Google Drive\n",
        "    google_drive = True #@param {type:\"boolean\"}\n",
        "    #@markdown Click here if you'd like to save the diffusion model checkpoint file to (and/or load from) your Google Drive:\n",
        "    save_models_to_google_drive = True #@param {type:\"boolean\"}\n",
        "except:\n",
        "    is_colab = False\n",
        "    google_drive = False\n",
        "    save_models_to_google_drive = False\n",
        "    print(\"Google Colab not detected.\")\n",
        "    is_kaggle = True if os.path.exists('/kaggle/working') else False\n",
        "if is_colab:\n",
        "    if google_drive is True and save_models_to_google_drive is True:\n",
        "        drive.mount('/content/drive')\n",
        "        ai_root = '/content/drive/MyDrive/Colab'\n",
        "        root_path = f'{ai_root}/respiratory'\n",
        "    else:\n",
        "        root_path = '/content'\n",
        "    true_root = root_path # not sure why the two paths\n",
        "else:\n",
        "    root_path = '/kaggle/working/' if is_kaggle else os.getcwd()\n",
        "    true_root = '/kaggle/working/' if is_kaggle else os.getcwd()\n",
        "\n",
        "print(f'Using this path as root: {true_root}')"
      ],
      "metadata": {
        "id": "y7GNecUJ8ShF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup\n",
        "\n",
        "repo_dir = \"repo\"\n",
        "\n",
        "now = datetime.datetime.now()\n",
        "def done(clear=False):\n",
        "    now = datetime.datetime.now()\n",
        "    if not clear:\n",
        "        clear_output(wait=False)\n",
        "    print(f\"done at {now.hour}:{now.minute}:{now.second}\")\n",
        "\n",
        "import os\n",
        "!pip install ipywidgets\n",
        "#!pip uninstall -y audio-diffusion-pytorch-trainer\n",
        "os.chdir(true_root)\n",
        "!rm -rf $repo_dir/\n",
        "#!git clone --branch NoLog https://github.com/twobob/audio-diffusion-pytorch-trainer\n",
        "#!git clone https://github.com/archinetai/audio-diffusion-pytorch-trainer\n",
        "!git clone https://github.com/endofu/audio-diffusion-pytorch-trainer $repo_dir\n",
        "os.chdir(f'{true_root}/{repo_dir}')\n",
        "!pip install -r requirements.txt\n",
        "if clear_logs_after_setup:\n",
        "  done()\n",
        "print('endofu/audio-diffusion-pytorch-trainer install completed')"
      ],
      "metadata": {
        "id": "e8Y_VJEI0X1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prompt_toolkit.layout import layout\n",
        "#@title Choose An Experiment\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import HBox, Label\n",
        "from ipywidgets import Layout, Button, Box, FloatText, Textarea, Dropdown, Label, IntSlider\n",
        "import time\n",
        "import pandas as pd\n",
        "out = widgets.Output()\n",
        "\n",
        "df = df = pd.DataFrame(columns = ['Dropdown_column', 'Float_column'])\n",
        "\n",
        "def list_files(your_directory):\n",
        "  return sorted( filter( lambda x: os.path.isfile(os.path.join(your_directory, x)), os.listdir(your_directory) ) )\n",
        "\n",
        "expdir=f'{true_root}/{repo_dir}/exp/'\n",
        "archdir=f'{true_root}/{repo_dir}/exp/archived/'\n",
        "current_dyamic_dir = expdir # presumes LIVE as default\n",
        "\n",
        "files = list_files(expdir)\n",
        "archives =  list_files(archdir)\n",
        "\n",
        "isYouTube = False\n",
        "\n",
        "def exp_loader(fully_qualified_filepath):\n",
        "  global isYouTube\n",
        "  with open(fully_qualified_filepath, 'r') as doc:\n",
        "    chomp = doc.read()\n",
        "    isYouTube = True if any( substring for substring in ['YoutubeDataset','CommonVoiceDataset','LibriSpeechDataset'] if substring in chomp   ) else False\n",
        "    return chomp\n",
        "\n",
        "def exp_writer(fully_qualified_filepath, string_text):\n",
        "  global isYouTube\n",
        "  with open(fully_qualified_filepath, 'w') as doc:\n",
        "    isYouTube = True if any( substring for substring in ['YoutubeDataset','CommonVoiceDataset','LibriSpeechDataset'] if substring in string_text   ) else False\n",
        "    doc.write(string_text)\n",
        "\n",
        "def get_button_layout():\n",
        "  return Layout(\n",
        "    display='inline-flex',\n",
        "    flex_flow='row',\n",
        "    justify_content='center',\n",
        "    padding = '5%',\n",
        "    align_items = 'flex-start'\n",
        ")\n",
        "\n",
        "def dropdown_handler(change):\n",
        "    global drop_down_input\n",
        "    drop_down_input = change.new\n",
        "    if change['type'] == 'change': dependent_drop_down.options=dependent_drop_down_elements[change.new]\n",
        "    current_dyamic_dir = expdir if drop_down.value=='LiveExperiments' else archdir\n",
        "\n",
        "\n",
        "def dep_dropdown_handler(change):\n",
        "    global EXPERIMENT\n",
        "    current_dyamic_dir = expdir if drop_down.value=='LiveExperiments' else archdir\n",
        "    editor.value = exp_loader(f'{current_dyamic_dir}{dependent_drop_down.value}')\n",
        "    EXPERIMENT = dependent_drop_down.value.replace('.yaml','')\n",
        "\n",
        "def on_edit_button_clicked(b):\n",
        "    editor.value = exp_loader(f'{current_dyamic_dir}/{dependent_drop_down.value}')\n",
        "    editor.layout.display = \"flex\"\n",
        "    editbutton.layout.display = \"none\"\n",
        "    savebutton.layout.display = \"flex\"\n",
        "\n",
        "def on_save_button_clicked(b):\n",
        "    global df\n",
        "    with out:\n",
        "      exp_writer(f'{current_dyamic_dir}/{dependent_drop_down.value}', editor.value)\n",
        "      editor.layout.display = \"none\"\n",
        "      savebutton.layout.display = \"none\"\n",
        "      editbutton.layout.display = \"flex\"\n",
        "\n",
        "form_item_layout = Layout(\n",
        "    display='flex',\n",
        "    flex_flow='row',\n",
        "    justify_content='space-between'\n",
        ")\n",
        "\n",
        "edit_button_item_layout = get_button_layout()\n",
        "\n",
        "button_item_layout = get_button_layout()\n",
        "button_item_layout.display = \"none\"\n",
        "\n",
        "#setup the default loaded experiment, hidden in the editor\n",
        "doctxt= exp_loader(f'{current_dyamic_dir}/{files[0]}')\n",
        "\n",
        "drop_down_input = 'LiveExperiments'\n",
        "drop_down = widgets.Dropdown(options=('LiveExperiments', 'ArchivedExperiments'),disabled=True) # Toggle for arch view\n",
        "\n",
        "dependent_drop_down_elements = {}\n",
        "dependent_drop_down_elements['LiveExperiments'] = files\n",
        "dependent_drop_down_elements['ArchivedExperiments'] = archives\n",
        "dependent_drop_down = widgets.Dropdown(options=(dependent_drop_down_elements['LiveExperiments']))\n",
        "\n",
        "drop_down.observe(dropdown_handler, names='value')\n",
        "dependent_drop_down.observe(dep_dropdown_handler, names='value')\n",
        "\n",
        "savebutton = widgets.Button(description='save experiment', layout=button_item_layout)\n",
        "savebutton.on_click(on_save_button_clicked)\n",
        "\n",
        "editbutton = widgets.Button(description='edit experiment', layout = edit_button_item_layout)\n",
        "editbutton.on_click(on_edit_button_clicked)\n",
        "\n",
        "editor  = widgets.Textarea(\n",
        "    value=doctxt,\n",
        "    placeholder='Edit Here',\n",
        "    description='Experiment:',\n",
        "    disabled=False,\n",
        "    layout=Layout(\n",
        "    display='none',\n",
        "    flex_flow='column',\n",
        "    border='solid 1px',\n",
        "    align_items='stretch',\n",
        "    width='100%',\n",
        "    height='800px',\n",
        "    padding = '1%'\n",
        ")\n",
        ")\n",
        "\n",
        "form_items = [\n",
        "    Box([Label(value='Experiment Editor'),\n",
        "         drop_down], layout=form_item_layout),\n",
        "    Box([Label(value='Choose an experiment to edit then run'),\n",
        "         dependent_drop_down], layout=form_item_layout),\n",
        "         editor,\n",
        "         editbutton,\n",
        "         savebutton\n",
        "        ]\n",
        "\n",
        "form = Box(form_items, layout=Layout(\n",
        "    display='flex',\n",
        "    flex_flow='column',\n",
        "    border='solid 1px',\n",
        "    align_items='stretch',\n",
        "    width='99%',\n",
        "    padding = '1%'\n",
        "))\n",
        "display(form)\n",
        "display(out)\n",
        "EXPERIMENT = dependent_drop_down.value.replace('.yaml','')"
      ],
      "metadata": {
        "id": "ejlsH-7P7LN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TMPENV = f'{true_root}/{repo_dir}/.env.tmp'\n",
        "LIVEENV = f'{true_root}/{repo_dir}/.env'\n",
        "!cp $TMPENV $LIVEENV\n",
        "#@title Setup paths, logins and logging\n",
        "#@markdown Setup the .env file options\n",
        "custom_log_path = 'logs'#@param {type: 'string'}\n",
        "custom_data_path = 'data-respiratory'#@param {type: 'string'}\n",
        "WANDB_PROJECT = 'femke-respiratory'#@param {type: 'string'}\n",
        "#@markdown weights and biases username\n",
        "#@markdown Required if using wandb logger\n",
        "WANDB_ENTITY = 'endofu'#@param {type: 'string'}\n",
        "#@markdown weights and biases API key\n",
        "WANDB_API_KEY = '---'#@param {type: 'string'}\n",
        "#@markdown huggingface API key\n",
        "#@markdown Required if using Common Voice dataset\n",
        "HUGGINGFACE_TOKEN = '---'#@param {type: 'string'}\n",
        "\n",
        "file = open(LIVEENV, \"r\")\n",
        "replacement = \"\"\n",
        "\n",
        "# using the for loop\n",
        "for count, line in enumerate(file):\n",
        "    line = line.strip()\n",
        "    if 0 == count:\n",
        "      line=  changes = f\"DIR_LOGS=/{custom_log_path}\"\n",
        "    if 1 == count:\n",
        "      line= changes = f\"DIR_DATA=/{custom_data_path}\"\n",
        "\n",
        "    changes = line.replace(\"WANDB_PROJECT=wandbprojectname\", f\"WANDB_PROJECT={WANDB_PROJECT}\")\n",
        "    changes = changes.replace(\"WANDB_ENTITY=wandbuser\", f\"WANDB_ENTITY={WANDB_ENTITY}\")\n",
        "    changes = changes.replace(\"WANDB_API_KEY=wandbapikey\", f\"WANDB_API_KEY={WANDB_API_KEY}\")\n",
        "    changes = changes.replace(\"HUGGINGFACE_TOKEN=huggingfacetoken\", f\"HUGGINGFACE_TOKEN={HUGGINGFACE_TOKEN}\")\n",
        "    replacement = replacement + changes + \"\\n\"\n",
        "with open(LIVEENV, 'w') as f:\n",
        "    f.write(replacement)\n",
        "f.close()\n",
        "os.chdir(true_root)\n",
        "if clear_logs_after_setup:\n",
        "  done()\n",
        "\n",
        "print('options set')"
      ],
      "metadata": {
        "id": "2YpLkcTW0iG3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%env  HYDRA_FULL_ERROR=1\n",
        "TRAIN_CMD = f'{true_root}/{repo_dir}/train.py'\n",
        "EXPERIMENT_CMD = f'exp={EXPERIMENT}'\n",
        "PATH_CMD = '' if isYouTube else f'++datamodule.dataset.path={true_root}/{custom_data_path}'\n",
        "CKPT = \"2023-09-26-19-58-27\"\n",
        "CKPT_CMD = f'+ckpt={true_root}/{custom_log_path}/ckpts/{CKPT}/last.ckpt' if CKPT else ''\n",
        "\n",
        "\n",
        "#@title Run the finetune\n",
        "## n GPU TRAINING with added data dir.\n",
        "\n",
        "os.chdir(true_root)\n",
        "print(f'Running the command: !python {true_root}/audio-diffusion-pytorch-trainer/train.py exp={EXPERIMENT} trainer.gpus=1 ++datamodule.dataset.path={true_root}/{custom_data_path}')\n",
        "!python $TRAIN_CMD $EXPERIMENT_CMD trainer.gpus=1 $PATH_CMD $CKPT_CMD\n"
      ],
      "metadata": {
        "id": "C46BxM-G6bEQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}